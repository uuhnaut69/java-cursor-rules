<?xml version="1.0" encoding="UTF-8"?>
<prompt xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:noNamespaceSchemaLocation="pml.xsd"
    id="131-java-unit-testing" version="1.0">

    <metadata>
        <!-- Markdown Front Matter for Cursor Rules -->
        <cursor-ai>
            <description></description>
            <globs></globs>
            <always-apply>false</always-apply>
        </cursor-ai>
        <tags>
            <tag>java</tag>
            <tag>unit-testing</tag>
            <tag>junit5</tag>
            <tag>assertj</tag>
            <tag>mockito</tag>
            <tag>testing</tag>
            <tag>best-practices</tag>
        </tags>
        <version>1.0.0</version>
        <title>Java Unit testing guidelines</title>
    </metadata>

    <role>You are a Senior software engineer with extensive experience in Java software development</role>

    <goal>
        Effective Java unit testing involves using JUnit 5 annotations and AssertJ for fluent assertions. Tests should follow the Given-When-Then structure with descriptive names for clarity. Each test must have a single responsibility, be independent, and leverage parameterized tests for data variations. Mocking dependencies with frameworks like Mockito is crucial for isolating the unit under test. While code coverage is a useful guide, the focus should be on meaningful tests for critical logic and edge cases. Test classes and methods should typically be package-private. Strategies for code splitting include small test methods and helper functions. Anti-patterns like testing implementation details, hard-coded values, and ignoring failures should be avoided. Proper state management involves isolated state and immutable objects, and error handling should include testing for expected exceptions and their messages.

        ### Implementing These Principles

        These guidelines are built upon the following core principles:

        1.  **Clarity and Readability**: Tests should be easy to understand. This is achieved through descriptive names (or `@DisplayName`), a clear Given-When-Then structure, and focused assertions. Readable tests serve as living documentation for the code under test.
        2.  **Isolation and Independence**: Each test must be self-contained, not relying on the state or outcome of other tests. Dependencies should be mocked to ensure the unit under test is validated in isolation. This leads to reliable and stable test suites.
        3.  **Comprehensive Validation**: Tests should thoroughly verify the behavior of the unit, including its responses to valid inputs, edge cases, boundary conditions, and error scenarios. This involves not just positive paths but also how the code handles failures and exceptions.
        4.  **Modern Tooling and Practices**: Leverage modern testing frameworks (JUnit 5), fluent assertion libraries (AssertJ), and mocking tools (Mockito) to write expressive, maintainable, and powerful tests. Utilize features like parameterized tests to reduce boilerplate and improve coverage of data variations.
        5.  **Maintainability and Focus**: Tests should be easy to maintain. This means avoiding tests that are too complex, test implementation details, or have multiple responsibilities. A well-written test makes it clear what is being tested and why, simplifying debugging and refactoring efforts.
    </goal>

    <examples>
        <toc auto-generate="true" />

        <example number="1" id="use-junit5-annotations">
            <example-header>
                <example-title>Use JUnit 5 Annotations</example-title>
                <example-subtitle>Prefer JUnit 5 annotations over JUnit 4</example-subtitle>
            </example-header>
            <example-description>
                <![CDATA[
                Utilize annotations from the `org.junit.jupiter.api` package (e.g., `@Test`, `@BeforeEach`, `@AfterEach`, `@DisplayName`, `@Nested`, `@Disabled`) instead of their JUnit 4 counterparts (`@org.junit.Test`, `@Before`, `@After`, `@Ignore`). This ensures consistency and allows leveraging the full capabilities of JUnit 5.
                ]]>
            </example-description>
            <code-examples>
                <good-example>
                    <code-block language="java"><![CDATA[import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.DisplayName;
import org.junit.jupiter.api.Test;
import static org.assertj.core.api.Assertions.assertThat;

@DisplayName("My Service Test")
class MyServiceTest {

    private MyService service;

    @BeforeEach
    void setUp() {
        service = new MyService(); // Setup executed before each test
    }

    @Test
    @DisplayName("should process data correctly")
    void processData() {
        // Given
        String input = "test";

        // When
        String result = service.process(input);

        // Then
        assertThat(result).isEqualTo("PROCESSED:test");
    }
}]]></code-block>
                </good-example>
                <bad-example>
                    <code-block language="java"><![CDATA[import org.junit.Before; // JUnit 4
import org.junit.Test;   // JUnit 4
import static org.junit.Assert.assertEquals; // JUnit 4 Assert

public class MyServiceTest {

    private MyService service;

    @Before // JUnit 4
    public void setup() {
        service = new MyService();
    }

    @Test // JUnit 4
    public void processData() {
        String input = "test";
        String result = service.process(input);
        assertEquals("PROCESSED:test", result); // JUnit 4 Assert
    }
}]]></code-block>
                </bad-example>
            </code-examples>
        </example>

        <example number="2" id="use-assertj-for-assertions">
            <example-header>
                <example-title>Use AssertJ for Assertions</example-title>
                <example-subtitle>Prefer AssertJ for assertions</example-subtitle>
            </example-header>
            <example-description>
                <![CDATA[
                Employ AssertJ's fluent API (`org.assertj.core.api.Assertions.assertThat`) for more readable, expressive, and maintainable assertions compared to JUnit Jupiter's `Assertions` class or Hamcrest matchers.
                ]]>
            </example-description>
            <code-examples>
                <good-example>
                    <code-block language="java"><![CDATA[import org.junit.jupiter.api.Test;
import static org.assertj.core.api.Assertions.assertThat;
import static org.assertj.core.api.Assertions.assertThatThrownBy;

class AssertJExampleTest {

    @Test
    void checkValue() {
        String result = "hello";
        assertThat(result)
            .isEqualTo("hello")
            .startsWith("hell")
            .endsWith("o")
            .hasSize(5); // Chain multiple assertions fluently
    }

    @Test
    void checkException() {
        MyService service = new MyService();
        assertThatThrownBy(() -> service.divide(1, 0)) // Preferred way to test exceptions
            .isInstanceOf(IllegalArgumentException.class)
            .hasMessageContaining("zero");
    }
}]]></code-block>
                </good-example>
                <bad-example>
                    <code-block language="java"><![CDATA[import org.junit.jupiter.api.Test;
import static org.junit.jupiter.api.Assertions.*; // JUnit Jupiter Assertions

class JUnitAssertionsExampleTest {

    @Test
    void checkValue() {
        String result = "hello";
        assertEquals("hello", result); // Less fluent
        assertTrue(result.startsWith("hell")); // Separate assertions for each property
        assertTrue(result.endsWith("o"));
        assertEquals(5, result.length());
    }

    @Test
    void checkException() {
        MyService service = new MyService();
        // More verbose exception testing
        IllegalArgumentException exception = assertThrows(
            IllegalArgumentException.class,
            () -> service.divide(1, 0)
        );
        assertTrue(exception.getMessage().contains("zero")); // Separate assertion for message
    }
}]]></code-block>
                </bad-example>
            </code-examples>
        </example>

        <example number="3" id="structure-tests-given-when-then">
            <example-header>
                <example-title>Structure Tests with Given-When-Then</example-title>
                <example-subtitle>Structure test methods using the Given-When-Then pattern</example-subtitle>
            </example-header>
            <example-description>
                <![CDATA[
                Organize the logic within test methods into three distinct, clearly separated phases: **Given** (setup preconditions), **When** (execute the code under test), and **Then** (verify the outcome). Use comments or empty lines to visually separate these phases, enhancing readability and understanding of the test's purpose.
                ]]>
            </example-description>
            <code-examples>
                <good-example>
                    <code-block language="java"><![CDATA[import org.junit.jupiter.api.Test;
import static org.assertj.core.api.Assertions.assertThat;

class GivenWhenThenTest {

    @Test
    void shouldCalculateSumCorrectly() {
        // Given
        Calculator calculator = new Calculator();
        int num1 = 5;
        int num2 = 10;
        int expectedSum = 15;

        // When
        int actualSum = calculator.add(num1, num2);

        // Then
        assertThat(actualSum).isEqualTo(expectedSum);
    }
}]]></code-block>
                </good-example>
                <bad-example>
                    <code-block language="java"><![CDATA[import org.junit.jupiter.api.Test;
import static org.assertj.core.api.Assertions.assertThat;

class UnstructuredTest {

    @Test
    void testAddition() {
        // Lack of clear separation makes it harder to follow the test flow
        Calculator calculator = new Calculator();
        assertThat(calculator.add(5, 10)).isEqualTo(15); // Combines action and verification
        // Setup might be mixed with action or verification elsewhere
    }
}]]></code-block>
                </bad-example>
            </code-examples>
        </example>

        <example number="4" id="use-descriptive-test-names">
            <example-header>
                <example-title>Use Descriptive Test Names</example-title>
                <example-subtitle>Write descriptive test method names or use @DisplayName</example-subtitle>
            </example-header>
            <example-description>
                <![CDATA[
                Test names should clearly communicate the scenario being tested and the expected outcome. Use either descriptive method names (e.g., following the `should_ExpectedBehavior_when_StateUnderTest` pattern) or JUnit 5's `@DisplayName` annotation for more natural language descriptions. This makes test reports easier to understand.
                ]]>
            </example-description>
            <code-examples>
                <good-example>
                    <code-block language="java"><![CDATA[@Test
void should_throwException_when_divisorIsZero() {
    // Given
    Calculator calculator = new Calculator();

    // When & Then
    assertThatThrownBy(() -> calculator.divide(1, 0))
        .isInstanceOf(ArithmeticException.class);
}

@Test
@DisplayName("Should return the correct sum for positive numbers")
void additionWithPositives() {
     // Given
     Calculator calculator = new Calculator();
     int num1 = 5;
     int num2 = 10;

     // When
     int actualSum = calculator.add(num1, num2);

     // Then
     assertThat(actualSum).isEqualTo(15);
}]]></code-block>
                </good-example>
                <bad-example>
                    <code-block language="java"><![CDATA[@Test
void testDivide() { // Name is too generic, doesn't explain the scenario
    // ... test logic ...
}

@Test
void test1() { // Uninformative name
    // ... test logic ...
}]]></code-block>
                </bad-example>
            </code-examples>
        </example>

        <example number="5" id="single-responsibility-in-tests">
            <example-header>
                <example-title>Aim for Single Responsibility in Tests</example-title>
                <example-subtitle>Each test method should verify a single logical concept</example-subtitle>
            </example-header>
            <example-description>
                <![CDATA[
                Avoid testing multiple unrelated things within a single test method. Each test should focus on one specific aspect of the unit's behavior or one particular scenario. This makes tests easier to understand, debug, and maintain. If a test fails, its specific focus makes pinpointing the cause simpler.
                ]]>
            </example-description>
            <code-examples>
                <good-example>
                    <code-block language="java"><![CDATA[// Separate tests for different validation aspects
@Test
void should_reject_when_emailIsNull() {
    // ... test logic for null email ...
}

@Test
void should_reject_when_emailFormatIsInvalid() {
    // ... test logic for invalid email format ...
}]]></code-block>
                </good-example>
                <bad-example>
                    <code-block language="java"><![CDATA[@Test
void testUserValidation() { // Tests multiple conditions at once
    // Given user with null email
    // ... assertion for null email ...

    // Given user with invalid email format
    // ... assertion for invalid format ...

    // Given user with valid email
    // ... assertion for valid email ...
}]]></code-block>
                </bad-example>
            </code-examples>
        </example>

        <example number="6" id="ensure-tests-are-independent">
            <example-header>
                <example-title>Ensure Tests are Independent</example-title>
                <example-subtitle>Tests must be independent and runnable in any order</example-subtitle>
            </example-header>
            <example-description>
                <![CDATA[
                Avoid creating tests that depend on the state left behind by previously executed tests. Each test should set up its own required preconditions (using `@BeforeEach` or within the test method itself) and should not rely on the execution order. This ensures test suite stability and reliability, preventing flickering tests.
                ]]>
            </example-description>
            <code-examples>
                <good-example>
                    <code-block language="java"><![CDATA[class IndependentTests {
    private MyRepository repository = new InMemoryRepository(); // Or use @BeforeEach

    @Test
    void should_findItem_when_itemExists() {
        // Given
        Item item = new Item("testId", "TestData");
        repository.save(item); // Setup specific to this test

        // When
        Optional<Item> found = repository.findById("testId");

        // Then
        assertThat(found).isPresent();
    }

    @Test
    void should_returnEmpty_when_itemDoesNotExist() {
        // Given - Repository is clean (or re-initialized via @BeforeEach)

        // When
        Optional<Item> found = repository.findById("nonExistentId");

        // Then
        assertThat(found).isNotPresent();
    }
}]]></code-block>
                </good-example>
                <bad-example>
                    <code-block language="java"><![CDATA[class DependentTests {
    private static MyRepository repository = new InMemoryRepository(); // Shared state
    private static Item savedItem;

    @Test // Test 1 (might run first)
    void testSave() {
        savedItem = new Item("testId", "Data");
        repository.save(savedItem);
        // ... assertions ...
    }

    @Test // Test 2 (depends on Test 1 having run)
    void testFind() {
        // This test fails if testSave() hasn't run or if run order changes
        Optional<Item> found = repository.findById("testId");
        assertThat(found).isPresent();
    }
}]]></code-block>
                </bad-example>
            </code-examples>
        </example>

        <example number="7" id="parameterized-tests">
            <example-header>
                <example-title>Use Parameterized Tests for Data Variations</example-title>
                <example-subtitle>Use @ParameterizedTest for testing the same logic with different inputs</example-subtitle>
            </example-header>
            <example-description>
                <![CDATA[
                When testing a method's behavior across various input values or boundary conditions, leverage JUnit 5's parameterized tests (`@ParameterizedTest` with sources like `@ValueSource`, `@CsvSource`, `@MethodSource`). This avoids code duplication and clearly separates the test logic from the test data.
                ]]>
            </example-description>
            <code-examples>
                <good-example>
                    <code-block language="java"><![CDATA[import org.junit.jupiter.params.ParameterizedTest;
import org.junit.jupiter.params.provider.CsvSource;
import static org.assertj.core.api.Assertions.assertThat;

class ParameterizedCalculatorTest {

    private final Calculator calculator = new Calculator();

    @ParameterizedTest(name = "{index} {0} + {1} = {2}") // Clear naming for each case
    @CsvSource({
        "1,  2,  3",
        "0,  0,  0",
        "-5, 5,  0",
        "10, -3, 7"
    })
    void additionTest(int a, int b, int expectedResult) {
        // Given inputs a, b (from @CsvSource)

        // When
        int actualResult = calculator.add(a, b);

        // Then
        assertThat(actualResult).isEqualTo(expectedResult);
    }
}]]></code-block>
                </good-example>
                <bad-example>
                    <code-block language="java"><![CDATA[import org.junit.jupiter.api.Test;
import static org.assertj.core.api.Assertions.assertThat;

class RepetitiveCalculatorTest {

    private final Calculator calculator = new Calculator();

    // Redundant tests for the same logic
    @Test
    void add1and2() {
        assertThat(calculator.add(1, 2)).isEqualTo(3);
    }

    @Test
    void add0and0() {
        assertThat(calculator.add(0, 0)).isEqualTo(0);
    }

    @Test
    void addNegative5and5() {
        assertThat(calculator.add(-5, 5)).isEqualTo(0);
    }

    @Test
    void add10andNegative3() {
        assertThat(calculator.add(10, -3)).isEqualTo(7);
    }
}]]></code-block>
                </bad-example>
            </code-examples>
        </example>

        <example number="8" id="utilize-mocking-dependencies">
            <example-header>
                <example-title>Utilize Mocking for Dependencies (Mockito)</example-title>
                <example-subtitle>Isolate the unit under test using mocking frameworks like Mockito</example-subtitle>
            </example-header>
            <example-description>
                <![CDATA[
                Unit tests should focus solely on the logic of the class being tested (System Under Test - SUT), not its dependencies (database, network services, other classes). Use mocking frameworks like Mockito to create mock objects that simulate the behavior of these dependencies. This ensures tests are fast, reliable, and truly test the unit in isolation.
                ]]>
            </example-description>
            <code-examples>
                <good-example>
                    <code-block language="java"><![CDATA[import org.junit.jupiter.api.Test;
import org.junit.jupiter.api.extension.ExtendWith;
import org.mockito.InjectMocks;
import org.mockito.Mock;
import org.mockito.junit.jupiter.MockitoExtension;

import java.util.Optional;

import static org.assertj.core.api.Assertions.assertThat;
import static org.mockito.Mockito.*;

@ExtendWith(MockitoExtension.class)
class UserServiceTest {

    @Mock
    private UserRepository userRepository;

    @InjectMocks
    private UserService userService;

    @Test
    @DisplayName("Should return user when found by id")
    void findUserById_Success() {
        // Given
        User expectedUser = new User("123", "John Doe");
        when(userRepository.findById("123")).thenReturn(Optional.of(expectedUser));

        // When
        Optional<User> actualUser = userService.findUserById("123");

        // Then
        assertThat(actualUser).isPresent().contains(expectedUser);
        verify(userRepository, times(1)).findById("123");
        verifyNoMoreInteractions(userRepository);
    }
}]]></code-block>
                </good-example>
                <bad-example>
                    <code-block language="java"><![CDATA[import org.junit.jupiter.api.Test;

class UserServiceTestBad {

    @Test
    void findUserById() {
        // Bad: Using real dependencies instead of mocks
        DatabaseConnection connection = new DatabaseConnection("localhost", 5432);
        UserRepository userRepository = new PostgresUserRepository(connection);
        UserService userService = new UserService(userRepository);

        // This test depends on database availability and state
        Optional<User> user = userService.findUserById("123");

        // Test is slow, brittle, and doesn't isolate the unit under test
        assertThat(user).isPresent();
    }
}]]></code-block>
                </bad-example>
            </code-examples>
        </example>

        <example number="9" id="test-coverage-guidance">
            <example-header>
                <example-title>Consider Test Coverage, But Don't Obsess</example-title>
                <example-subtitle>Use code coverage as a guide, not a definitive quality metric</example-subtitle>
            </example-header>
            <example-description>
                <![CDATA[
                Tools like JaCoCo can measure which lines of code are executed by your tests (code coverage). Aiming for high coverage (e.g., >80% line/branch coverage) is generally good practice, as it indicates most code paths are tested. However, 100% coverage doesn't guarantee bug-free code or high-quality tests. Focus on writing meaningful tests for critical logic and edge cases rather than solely chasing coverage numbers. A test might cover a line but not actually verify its correctness effectively.
                ]]>
            </example-description>
        </example>

        <example number="10" id="test-scopes">
            <example-header>
                <example-title>Test Scopes</example-title>
                <example-subtitle>Package-private visibility for test classes and methods</example-subtitle>
            </example-header>
            <example-description>
                <![CDATA[
                Test classes should have package-private visibility. There is no need for them to be public. Test methods should also have package-private visibility. There is no need for them to be public.
                ]]>
            </example-description>
        </example>

        <example number="11" id="code-splitting-strategies">
            <example-header>
                <example-title>Code Splitting Strategies</example-title>
                <example-subtitle>Organize test code effectively</example-subtitle>
            </example-header>
            <example-description>
                <![CDATA[
                - **Small Test Methods:** Keep test methods small and focused on testing a single behavior.
                - **Helper Methods:** Use helper methods to avoid code duplication in test setup and assertions.
                - **Parameterized Tests:** Utilize JUnit's parameterized tests to test the same logic with different input values.
                ]]>
            </example-description>
        </example>

        <example number="12" id="anti-patterns-code-smells">
            <example-header>
                <example-title>Anti-patterns and Code Smells</example-title>
                <example-subtitle>Common testing mistakes to avoid</example-subtitle>
            </example-header>
            <example-description>
                <![CDATA[
                - **Testing Implementation Details:** Avoid testing implementation details that might change, leading to brittle tests. Focus on testing behavior and outcomes.
                - **Hard-coded Values:** Avoid hard-coding values in tests. Use constants or test data to make tests more maintainable.
                - **Complex Test Logic:** Keep test logic simple and avoid complex calculations or conditional statements within tests.
                - **Ignoring Edge Cases:** Don't ignore edge cases or boundary conditions. Ensure tests cover a wide range of inputs, including invalid or unexpected values.
                - **Slow Tests:** Avoid slow tests that discourage developers from running them frequently.
                - **Over-reliance on Mocks:** Mock judiciously; too many mocks can obscure the actual behavior and make tests less reliable.
                - **Ignoring Test Failures:** Never ignore failing tests. Investigate and fix them promptly.
                ]]>
            </example-description>
        </example>

        <example number="13" id="state-management">
            <example-header>
                <example-title>State Management</example-title>
                <example-subtitle>Managing test state effectively</example-subtitle>
            </example-header>
            <example-description>
                <![CDATA[
                - **Isolated State:** Ensure each test has its own isolated state to avoid interference between tests. Use `@BeforeEach` to reset the state before each test.
                - **Immutable Objects:** Prefer immutable objects to simplify state management and avoid unexpected side effects.
                - **Stateless Components:** Design stateless components whenever possible to reduce the need for state management in tests.
                ]]>
            </example-description>
        </example>

        <example number="14" id="error-handling">
            <example-header>
                <example-title>Error Handling</example-title>
                <example-subtitle>Testing exception scenarios effectively</example-subtitle>
            </example-header>
            <example-description>
                <![CDATA[
                - **Expected Exceptions:** Use AssertJ's `assertThatThrownBy` to verify that a method throws the expected exception under specific conditions.
                - **Exception Messages:** Assert the exception message to ensure the correct error is being thrown with helpful context.
                - **Graceful Degradation:** Test how the application handles errors and gracefully degrades when dependencies are unavailable.
                ]]>
            </example-description>
        </example>

        <example number="15" id="jspecify-null-safety">
            <example-header>
                <example-title>Leverage JSpecify for Null Safety</example-title>
                <example-subtitle>Utilize JSpecify annotations for explicit nullness contracts</example-subtitle>
            </example-header>
            <example-description>
                <![CDATA[
                Employ JSpecify annotations (`org.jspecify.annotations.*`) such as `@NullMarked`, `@Nullable`, and `@NonNull` to clearly define the nullness expectations of method parameters, return types, and fields within your tests and the code under test. This practice enhances code clarity, enables static analysis tools to catch potential `NullPointerExceptions` early, and improves the overall robustness of your tests and application code.
                ]]>
            </example-description>
            <code-examples>
                <good-example>
                    <code-block language="java"><![CDATA[@NullMarked
@ExtendWith(MockitoExtension.class)
class MyProcessorTest {

    @Mock
    private DataService mockDataService;

    private MyProcessor myProcessor;

    @Test
    void should_handleNullData_when_serviceReturnsNull() {
        // Given
        myProcessor = new MyProcessor(mockDataService);
        String key = "testKey";
        when(mockDataService.getData(key)).thenReturn(null);
        when(mockDataService.processData(null)).thenReturn("processed:null");

        // When
        String result = myProcessor.execute(key);

        // Then
        assertThat(result).isEqualTo("processed:null");
    }
}]]></code-block>
                </good-example>
                <bad-example>
                    <code-block language="java"><![CDATA[// No JSpecify annotations, nullness is ambiguous
class MyProcessorTest {
    @Test
    void testProcessing() {
        // Ambiguity: if getData returns null, this test might pass or fail unexpectedly
        when(mockDataService.getData(key)).thenReturn("someData");
        when(mockDataService.processData("SOMEDATA")).thenReturn("processed:SOMEDATA");

        String result = myProcessor.execute(key);

        assertThat(result).isEqualTo("processed:SOMEDATA");
    }
}]]></code-block>
                </bad-example>
            </code-examples>
        </example>

        <example number="16" id="right-bicep">
            <example-header>
                <example-title>Key Questions to Guide Test Creation (RIGHT-BICEP)</example-title>
                <example-subtitle>Comprehensive testing approach using RIGHT-BICEP</example-subtitle>
            </example-header>
            <example-description>
                <![CDATA[
                - If the code ran correctly, how would I know?
                - How am I going to test this?
                - What else can go wrong?
                - Could this same kind of problem happen anywhere else?
                - What to Test: Use Your RIGHT-BICEP
                  - Are the results **Right**?
                  - Are all the **Boundary** conditions CORRECT?
                  - Can you check **Inverse** relationships?
                  - Can you **Cross-check** results using other means?
                  - Can you force **Error** conditions to happen?
                  - Are **Performance** characteristics within bounds?
                ]]>
            </example-description>
            <code-examples>
                <good-example>
                    <code-block language="java"><![CDATA[public class CalculatorTest {

    private final Calculator calculator = new Calculator();

    // R - Right results
    @Test
    void add_simplePositiveNumbers_returnsCorrectSum() {
        assertThat(calculator.add(2, 3)).isEqualTo(5);
    }

    // B - Boundary conditions
    @Test
    void add_numberAndZero_returnsNumber() {
        assertThat(calculator.add(5, 0)).isEqualTo(5);
    }

    @Test
    void add_nearMaxInteger_returnsCorrectSum() {
        assertThat(calculator.add(Integer.MAX_VALUE - 1, 1)).isEqualTo(Integer.MAX_VALUE);
    }

    // C - Cross-check (commutative property)
    @Test
    void add_commutativeProperty_holdsTrue() {
        assertThat(calculator.add(2, 3)).isEqualTo(calculator.add(3, 2));
    }

    // E - Error conditions (overflow)
    @Test
    void add_integerOverflow_throwsArithmeticException() {
        assertThatThrownBy(() -> calculator.add(Integer.MAX_VALUE, 1))
            .isInstanceOf(ArithmeticException.class)
            .hasMessageContaining("overflow");
    }
}]]></code-block>
                </good-example>
                <bad-example>
                    <code-block language="java"><![CDATA[// Test only covers one simple case
public class CalculatorTestPoor {
    private final Calculator calculator = new Calculator();

    @Test
    void add_basicTest() {
        assertThat(calculator.add(2, 2)).isEqualTo(4); // Only testing one happy path
    }
}]]></code-block>
                </bad-example>
            </code-examples>
        </example>

        <example number="17" id="a-trip">
            <example-header>
                <example-title>Characteristics of Good Tests (A-TRIP)</example-title>
                <example-subtitle>Ensuring tests follow A-TRIP principles</example-subtitle>
            </example-header>
            <example-description>
                <![CDATA[
                Good tests are A-TRIP:
                - **Automatic**: Tests should run without human intervention.
                - **Thorough**: Test everything that could break; cover edge cases.
                - **Repeatable**: Tests should produce the same results every time, in any environment.
                - **Independent**: Tests should not rely on each other or on the order of execution.
                - **Professional**: Test code is real code; keep it clean, maintainable, and well-documented.
                ]]>
            </example-description>
            <code-examples>
                <good-example>
                    <code-block language="java"><![CDATA[public class OrderProcessorTest {

    private OrderProcessor processor;

    // Automatic: Part of JUnit test suite, runs with build tools.
    // Independent: Each test sets up its own state.
    @BeforeEach
    void setUp() {
        processor = new OrderProcessor(); // Fresh instance for each test
    }

    // Thorough: Testing adding valid items.
    @Test
    void addItem_validItem_increasesCount() {
        processor.addItem("Laptop");
        assertThat(processor.getItemCount()).isEqualTo(1);
        processor.addItem("Mouse");
        assertThat(processor.getItemCount()).isEqualTo(2);
    }

    // Thorough: Testing an edge case (adding null).
    @Test
    void addItem_nullItem_throwsIllegalArgumentException() {
        assertThatThrownBy(() -> processor.addItem(null))
            .isInstanceOf(IllegalArgumentException.class);
    }

    // Professional: Code is clean, uses meaningful names, follows conventions.
}]]></code-block>
                </good-example>
                <bad-example>
                    <code-block language="java"><![CDATA[public class BadOrderProcessorTest {
    // Violates Independent: static processor shared between tests
    private static OrderProcessor sharedProcessor = new OrderProcessor();

    @Test
    void test1_addItem() {
        // Assumes this runs first or that sharedProcessor is empty.
        sharedProcessor.addItem("Book");
        assertThat(sharedProcessor.getItemCount()).isEqualTo(1); // Might fail if other tests run first
    }

    @Test
    void test2_addAnotherItem() {
        sharedProcessor.addItem("Pen");
        // The expected count depends on whether test1_addItem ran and succeeded.
        assertThat(sharedProcessor.getItemCount()).isGreaterThan(0); // Weak assertion
    }
}]]></code-block>
                </bad-example>
            </code-examples>
        </example>

        <example number="18" id="correct-boundary-conditions">
            <example-header>
                <example-title>Verifying CORRECT Boundary Conditions</example-title>
                <example-subtitle>Comprehensive boundary condition testing using CORRECT</example-subtitle>
            </example-header>
            <example-description>
                <![CDATA[
                Ensure your tests check the following boundary conditions (CORRECT):
                - **Conformance**: Does the value conform to an expected format?
                - **Ordering**: Is the set of values ordered or unordered as appropriate?
                - **Range**: Is the value within reasonable minimum and maximum values?
                - **Reference**: Does the code reference anything external that isn't under direct control?
                - **Existence**: Does the value exist? (e.g., is non-null, non-zero, present in a set)
                - **Cardinality**: Are there exactly enough values?
                - **Time**: Is everything happening in order? At the right time? In time?
                ]]>
            </example-description>
            <code-examples>
                <good-example>
                    <code-block language="java"><![CDATA[public class UserValidationTest {
    private final UserValidation validator = new UserValidation();

    // Testing Range for age
    @Test
    void isAgeValid_ageAtLowerBound_returnsTrue() {
        assertThat(validator.isAgeValid(18)).isTrue();
    }

    @Test
    void isAgeValid_ageAtUpperBound_returnsTrue() {
        assertThat(validator.isAgeValid(120)).isTrue();
    }

    @Test
    void isAgeValid_ageBelowLowerBound_returnsFalse() {
        assertThat(validator.isAgeValid(17)).isFalse();
    }

    // Testing Conformance for email
    @ParameterizedTest
    @ValueSource(strings = {"user@example.com", "user.name@sub.example.co.uk"})
    void isValidEmailFormat_validEmails_returnsTrue(String email) {
        assertThat(validator.isValidEmailFormat(email)).isTrue();
    }

    @ParameterizedTest
    @ValueSource(strings = {"userexample.com", "user@", "@example.com"})
    void isValidEmailFormat_invalidEmails_returnsFalse(String email) {
        assertThat(validator.isValidEmailFormat(email)).isFalse();
    }

    // Testing Existence for username
    @Test
    void processUsername_nullUsername_returnsFalse() {
        assertThat(validator.processUsername(null)).isFalse();
    }

    @Test
    void processUsername_emptyUsername_returnsFalse() {
        assertThat(validator.processUsername("")).isFalse();
    }
}]]></code-block>
                </good-example>
                <bad-example>
                    <code-block language="java"><![CDATA[// Only testing one happy path for age validation, ignoring boundaries.
public class UserValidationPoorTest {
    private final UserValidation validator = new UserValidation();

    @Test
    void isAgeValid_typicalAge_returnsTrue() {
        assertThat(validator.isAgeValid(25)).isTrue(); // Only one value tested
    }

    @Test
    void isValidEmailFormat_typicalEmail_returnsTrue() {
        assertThat(validator.isValidEmailFormat("test@example.com")).isTrue(); // No invalid formats, no nulls
    }
}]]></code-block>
                </bad-example>
            </code-examples>
        </example>
    </examples>
</prompt>
